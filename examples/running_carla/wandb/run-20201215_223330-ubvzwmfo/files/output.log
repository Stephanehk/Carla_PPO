Episode reward: -426
Traceback (most recent call last):
  File "run_ppo.py", line 279, in <module>
    main(**vars(parser.parse_args()))
  File "run_ppo.py", line 268, in main
    train_PPO(host,world_port)
  File "run_ppo.py", line 252, in train_PPO
    loss = float(-torch.min(update1,update2) + 0.5*mse(state_values,rewards) - 0.001*entropies)
ValueError: only one element tensors can be converted to Python scalars
